{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel, Matern\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import check_random_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `EXTENDED_EVALUATION` to `True` in order to visualize your predictions.\n",
    "EXTENDED_EVALUATION = False\n",
    "EVALUATION_GRID_POINTS = 300  # Number of grid points used in extended evaluation\n",
    "\n",
    "# Cost function constants\n",
    "COST_W_UNDERPREDICT = 50.0\n",
    "COST_W_NORMAL = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    \"\"\"\n",
    "    Model for this task.\n",
    "    You need to implement the train_model and generate_predictions methods\n",
    "    without changing their signatures, but are allowed to create additional methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method=\"full\", undersample_ratio=0.1, n_inducing=200, n_clusters=10):\n",
    "        \"\"\"\n",
    "        Initialize your model here.\n",
    "        We already provide a random number generator for reproducibility.\n",
    "        \"\"\"\n",
    "        self.rng = np.random.default_rng(seed=0)\n",
    "        self.method = method\n",
    "        self.undersample_ratio = undersample_ratio\n",
    "        self.n_inducing = n_inducing\n",
    "        self.n_clusters = n_clusters\n",
    "        self.local_gps = []\n",
    "        self.gp = None\n",
    "\n",
    "    def generate_predictions(self, test_coordinates: np.ndarray, test_area_flags: np.ndarray) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Predict the pollution concentration for a given set of city_areas.\n",
    "        :param test_coordinates: city_areas as a 2d NumPy float array of shape (NUM_SAMPLES, 2)\n",
    "        :param test_area_flags: city_area info for every sample in a form of a bool array (NUM_SAMPLES,)\n",
    "        :return:\n",
    "            Tuple of three 1d NumPy float arrays, each of shape (NUM_SAMPLES,),\n",
    "            containing your predictions, the GP posterior mean, and the GP posterior stddev (in that order)\n",
    "        \"\"\"\n",
    "\n",
    "        if self.method == \"nystrom\":\n",
    "            # Generate predictions using Nyström approximation\n",
    "            Kmn = RBF()(self.inducing_points, test_coordinates)\n",
    "            gp_mean = np.dot(self.alpha, Kmn)\n",
    "            gp_std = np.zeros_like(gp_mean)  # For now, no stddev for approximation\n",
    "            predictions = gp_mean\n",
    "\n",
    "        elif self.method == \"local_gps\":\n",
    "            # Generate predictions using the nearest local GP for each test point\n",
    "            kmeans = KMeans(n_clusters=self.n_clusters)\n",
    "            test_labels = kmeans.predict(test_coordinates)\n",
    "\n",
    "            gp_mean = np.zeros(test_coordinates.shape[0])\n",
    "            gp_std = np.zeros(test_coordinates.shape[0])\n",
    "\n",
    "            for i in range(self.n_clusters):\n",
    "                cluster_indices = np.where(test_labels == i)[0]\n",
    "                if len(cluster_indices) > 0:\n",
    "                    gp_mean[cluster_indices], gp_std[cluster_indices] = self.local_gps[i].predict(test_coordinates[cluster_indices], return_std=True)\n",
    "\n",
    "            predictions = gp_mean\n",
    "\n",
    "        elif self.gp is not None:\n",
    "            # Full GP predictions\n",
    "            gp_mean, gp_std = self.gp.predict(test_coordinates, return_std=True)\n",
    "            predictions = gp_mean\n",
    "\n",
    "        else:\n",
    "            raise RuntimeError(\"No trained model available for generating predictions.\")\n",
    "        \n",
    "        # Asymmetric cost adjustment for residential areas\n",
    "        residential_area_mask = test_area_flags == 1  # Boolean mask for residential areas (area_id == 1)\n",
    "\n",
    "        # Apply both bias and quantile adjustment in residential areas\n",
    "        bias_factor = 0.3  # Bias factor for the stddev (can be tuned)\n",
    "        z_90 = 1.28  # z-score for 90th percentile\n",
    "\n",
    "        # Adjust predictions in residential areas\n",
    "        predictions[residential_area_mask] = (\n",
    "            gp_mean[residential_area_mask] \n",
    "            + bias_factor * gp_std[residential_area_mask]  # Add bias factor\n",
    "            + z_90 * gp_std[residential_area_mask]  # Add quantile adjustment\n",
    "        )\n",
    "\n",
    "        return predictions, gp_mean, gp_std\n",
    "    \n",
    "    def undersample_data(coordinates: np.ndarray, targets: np.ndarray, area_flags: np.ndarray, ratio: float = 0.1):\n",
    "        \"\"\"\n",
    "        Undersample the dataset by randomly selecting a subset of the data.\n",
    "        :param coordinates: 2D coordinates of the data points.\n",
    "        :param targets: PM2.5 target values.\n",
    "        :param area_flags: Binary flags for residential areas (1) or non-residential areas (0).\n",
    "        :param ratio: Fraction of data to keep (e.g., 0.1 for 10% of the data).\n",
    "        :return: Undersampled coordinates, targets, and area flags.\n",
    "        \"\"\"\n",
    "        num_samples = int(len(coordinates) * ratio)\n",
    "        indices = np.random.choice(len(coordinates), num_samples, replace=False)\n",
    "\n",
    "        undersampled_coordinates = coordinates[indices]\n",
    "        undersampled_targets = targets[indices]\n",
    "        undersampled_area_flags = area_flags[indices]\n",
    "\n",
    "        return undersampled_coordinates, undersampled_targets, undersampled_area_flags\n",
    "\n",
    "    def partition_data_with_kmeans(coordinates: np.ndarray, n_clusters: int = 10):\n",
    "        \"\"\"\n",
    "        Partition the data into clusters using KMeans for training multiple local GPs.\n",
    "        :param coordinates: 2D coordinates of the data points.\n",
    "        :param n_clusters: Number of clusters to create.\n",
    "        :return: Cluster labels and the trained k-means model.\n",
    "        \"\"\"\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(coordinates)\n",
    "        labels = kmeans.labels_\n",
    "        \n",
    "        return labels, kmeans\n",
    "    \n",
    "    def nystrom_approximation(coordinates: np.ndarray, targets: np.ndarray, n_inducing: int = 200):\n",
    "        \"\"\"\n",
    "        Perform the Nyström method to approximate the kernel matrix.\n",
    "        :param coordinates: 2D coordinates of the data points.\n",
    "        :param targets: PM2.5 target values.\n",
    "        :param n_inducing: Number of inducing points to use for the approximation.\n",
    "        :return: Coordinates of inducing points, the approximated kernel matrix, and the targets.\n",
    "        \"\"\"\n",
    "        rng = check_random_state(42)\n",
    "        inducing_indices = rng.choice(len(coordinates), n_inducing, replace=False)\n",
    "        inducing_points = coordinates[inducing_indices]\n",
    "\n",
    "        # Approximate the kernel matrix using the inducing points\n",
    "        Kmm = RBF()(inducing_points)  # Kernel matrix for inducing points\n",
    "        Kmn = RBF()(inducing_points, coordinates)  # Cross kernel matrix\n",
    "        Kmm_inv = np.linalg.inv(Kmm)\n",
    "\n",
    "        # Predictive mean\n",
    "        alpha = np.dot(Kmm_inv, np.dot(Kmn, targets))\n",
    "        \n",
    "        return inducing_points, alpha\n",
    "\n",
    "    def train_model(self, train_targets: np.ndarray, train_coordinates: np.ndarray, train_area_flags: np.ndarray):\n",
    "        \"\"\"\n",
    "        Fit your model on the given training data.\n",
    "        :param train_coordinates: Training features as a 2d NumPy float array of shape (NUM_SAMPLES, 2)\n",
    "        :param train_targets: Training pollution concentrations as a 1d NumPy float array of shape (NUM_SAMPLES,)\n",
    "        :param train_area_flags: Binary variable denoting whether the 2D training point is in the residential area (1) or not (0)\n",
    "        \"\"\"\n",
    "        if self.method == \"undersample\":\n",
    "            print(\"Applying undersampling...\")\n",
    "            train_coordinates, train_targets, train_area_flags = self.undersample_data(train_coordinates, train_targets, train_area_flags, ratio=self.undersample_ratio)\n",
    "\n",
    "        elif self.method == \"nystrom\":\n",
    "            print(\"Applying Nyström kernel approximation...\")\n",
    "            inducing_points, alpha = self.nystrom_approximation(train_coordinates, train_targets, n_inducing=self.n_inducing)\n",
    "            self.inducing_points = inducing_points  # Store inducing points for later predictions\n",
    "            self.alpha = alpha\n",
    "\n",
    "        elif self.method == \"local_gps\":\n",
    "            print(\"Applying multiple local GPs...\")\n",
    "            labels, kmeans = self.partition_data_with_kmeans(train_coordinates, n_clusters=self.n_clusters)\n",
    "\n",
    "            # Train a separate GP for each cluster\n",
    "            for i in range(self.n_clusters):\n",
    "                cluster_indices = np.where(labels == i)[0]\n",
    "                gp = GaussianProcessRegressor(kernel=RBF(), alpha=0.0, n_restarts_optimizer=5)\n",
    "                gp.fit(train_coordinates[cluster_indices], train_targets[cluster_indices])\n",
    "                self.local_gps.append(gp)\n",
    "\n",
    "        else:\n",
    "            # Full dataset GP (no scaling techniques)\n",
    "            kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2)) + WhiteKernel(noise_level=1)\n",
    "            self.gp = GaussianProcessRegressor(kernel=kernel, alpha=0.0, n_restarts_optimizer=5)\n",
    "            self.gp.fit(train_coordinates, train_targets)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't have to change this function\n",
    "def calculate_cost(ground_truth: np.ndarray, predictions: np.ndarray, area_flags: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the cost of a set of predictions.\n",
    "\n",
    "    :param ground_truth: Ground truth pollution levels as a 1d NumPy float array\n",
    "    :param predictions: Predicted pollution levels as a 1d NumPy float array\n",
    "    :param area_flags: city_area info for every sample in a form of a bool array (NUM_SAMPLES,)\n",
    "    :return: Total cost of all predictions as a single float\n",
    "    \"\"\"\n",
    "    assert ground_truth.ndim == 1 and predictions.ndim == 1 and ground_truth.shape == predictions.shape\n",
    "\n",
    "    # Unweighted cost\n",
    "    cost = (ground_truth - predictions) ** 2\n",
    "    weights = np.ones_like(cost) * COST_W_NORMAL\n",
    "\n",
    "    # Case i): underprediction\n",
    "    mask = (predictions < ground_truth) & [bool(area_flag) for area_flag in area_flags]\n",
    "    weights[mask] = COST_W_UNDERPREDICT\n",
    "\n",
    "    # Weigh the cost and return the average\n",
    "    return np.mean(cost * weights)\n",
    "\n",
    "\n",
    "# You don't have to change this function\n",
    "def check_within_circle(coordinate, circle_parameters):\n",
    "    \"\"\"\n",
    "    Checks if a coordinate is inside a circle.\n",
    "    :param coordinate: 2D coordinate\n",
    "    :param circle_parameters: 3D coordinate of the circle center and its radius\n",
    "    :return: True if the coordinate is inside the circle, False otherwise\n",
    "    \"\"\"\n",
    "    return (coordinate[0] - circle_parameters[0])**2 + (coordinate[1] - circle_parameters[1])**2 < circle_parameters[2]**2\n",
    "\n",
    "# You don't have to change this function \n",
    "def identify_city_area_flags(grid_coordinates):\n",
    "    \"\"\"\n",
    "    Determines the city_area index for each coordinate in the visualization grid.\n",
    "    :param grid_coordinates: 2D coordinates of the visualization grid\n",
    "    :return: 1D array of city_area indexes\n",
    "    \"\"\"\n",
    "    # Circles coordinates\n",
    "    circles = np.array([[0.5488135, 0.71518937, 0.17167342],\n",
    "                    [0.79915856, 0.46147936, 0.1567626 ],\n",
    "                    [0.26455561, 0.77423369, 0.10298338],\n",
    "                    [0.6976312,  0.06022547, 0.04015634],\n",
    "                    [0.31542835, 0.36371077, 0.17985623],\n",
    "                    [0.15896958, 0.11037514, 0.07244247],\n",
    "                    [0.82099323, 0.09710128, 0.08136552],\n",
    "                    [0.41426299, 0.0641475,  0.04442035],\n",
    "                    [0.09394051, 0.5759465,  0.08729856],\n",
    "                    [0.84640867, 0.69947928, 0.04568374],\n",
    "                    [0.23789282, 0.934214,   0.04039037],\n",
    "                    [0.82076712, 0.90884372, 0.07434012],\n",
    "                    [0.09961493, 0.94530153, 0.04755969],\n",
    "                    [0.88172021, 0.2724369,  0.04483477],\n",
    "                    [0.9425836,  0.6339977,  0.04979664]])\n",
    "    \n",
    "    area_flags = np.zeros((grid_coordinates.shape[0],))\n",
    "\n",
    "    for i,coordinate in enumerate(grid_coordinates):\n",
    "        area_flags[i] = any([check_within_circle(coordinate, circ) for circ in circles])\n",
    "\n",
    "    return area_flags\n",
    "\n",
    "# You don't have to change this function\n",
    "def execute_extended_evaluation(model: Model, output_dir: str = '/results'):\n",
    "    \"\"\"\n",
    "    Visualizes the predictions of a fitted model.\n",
    "    :param model: Fitted model to be visualized\n",
    "    :param output_dir: Directory in which the visualizations will be stored\n",
    "    \"\"\"\n",
    "    print('Performing extended evaluation')\n",
    "\n",
    "    # Visualize on a uniform grid over the entire coordinate system\n",
    "    grid_lat, grid_lon = np.meshgrid(\n",
    "        np.linspace(0, EVALUATION_GRID_POINTS - 1, num=EVALUATION_GRID_POINTS) / EVALUATION_GRID_POINTS,\n",
    "        np.linspace(0, EVALUATION_GRID_POINTS - 1, num=EVALUATION_GRID_POINTS) / EVALUATION_GRID_POINTS,\n",
    "    )\n",
    "    visualization_grid = np.stack((grid_lon.flatten(), grid_lat.flatten()), axis=1)\n",
    "    grid_area_flags = identify_city_area_flags(visualization_grid)\n",
    "    \n",
    "    # Obtain predictions, means, and stddevs over the entire map\n",
    "    predictions, gp_mean, gp_stddev = model.generate_predictions(visualization_grid, grid_area_flags)\n",
    "    predictions = np.reshape(predictions, (EVALUATION_GRID_POINTS, EVALUATION_GRID_POINTS))\n",
    "    gp_mean = np.reshape(gp_mean, (EVALUATION_GRID_POINTS, EVALUATION_GRID_POINTS))\n",
    "\n",
    "    vmin, vmax = 0.0, 65.0\n",
    "\n",
    "    # Plot the actual predictions\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Extended visualization of task 1')\n",
    "    im = ax.imshow(predictions, vmin=vmin, vmax=vmax)\n",
    "    cbar = fig.colorbar(im, ax=ax)\n",
    "\n",
    "    # Save figure to pdf\n",
    "    figure_path = os.path.join(output_dir, 'extended_evaluation.pdf')\n",
    "    fig.savefig(figure_path)\n",
    "    print(f'Saved extended evaluation to {figure_path}')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def extract_area_information(train_x: np.ndarray, test_x: np.ndarray) -> typing.Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts the city_area information from the training and test features.\n",
    "    :param train_x: Training features\n",
    "    :param test_x: Test features\n",
    "    :return: Tuple of (training features' 2D coordinates, training features' city_area information,\n",
    "        test features' 2D coordinates, test features' city_area information)\n",
    "    \"\"\"\n",
    "    \n",
    "    train_coordinates = train_x[:, :2]\n",
    "    test_coordinates = test_x[:, :2]\n",
    "    train_area_flags = train_x[:, 2].astype(bool)\n",
    "    test_area_flags = test_x[:, 2].astype(bool)  \n",
    "\n",
    "\n",
    "    assert train_coordinates.shape[0] == train_area_flags.shape[0] and test_coordinates.shape[0] == test_area_flags.shape[0]\n",
    "    assert train_coordinates.shape[1] == 2 and test_coordinates.shape[1] == 2\n",
    "    assert train_area_flags.ndim == 1 and test_area_flags.ndim == 1\n",
    "\n",
    "    return train_coordinates, train_area_flags, test_coordinates, test_area_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m         execute_extended_evaluation(model, output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m Model()\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_coordinates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_area_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Predict on the test features\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicting on test features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 161\u001b[0m, in \u001b[0;36mModel.train_model\u001b[0;34m(self, train_targets, train_coordinates, train_area_flags)\u001b[0m\n\u001b[1;32m    159\u001b[0m kernel \u001b[38;5;241m=\u001b[39m RBF(length_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, length_scale_bounds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m1e2\u001b[39m)) \u001b[38;5;241m+\u001b[39m WhiteKernel(noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgp \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(kernel\u001b[38;5;241m=\u001b[39mkernel, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_coordinates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:303\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_marginal_likelihood(theta, clone_kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# First optimize starting from theta specified in kernel\u001b[39;00m\n\u001b[1;32m    301\u001b[0m optima \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    302\u001b[0m     (\n\u001b[0;32m--> 303\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbounds\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[1;32m    307\u001b[0m ]\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# Additional runs are performed from log-uniform chosen initial\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# theta\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:652\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 652\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    660\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py:306\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[0;32m--> 306\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_scalar_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_bounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[1;32m    312\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/optimize.py:261\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    257\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m sf \u001b[38;5;241m=\u001b[39m \u001b[43mScalarFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfinite_diff_rel_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:140\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[0;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     73\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/optimize/optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:293\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 293\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:583\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    581\u001b[0m K[np\u001b[38;5;241m.\u001b[39mdiag_indices_from(K)] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 583\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mcholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGPR_CHOLESKY_LOWER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39mzeros_like(theta)) \u001b[38;5;28;01mif\u001b[39;00m eval_gradient \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/linalg/decomp_cholesky.py:88\u001b[0m, in \u001b[0;36mcholesky\u001b[0;34m(a, lower, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcholesky\u001b[39m(a, lower\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, overwrite_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, check_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    Compute the Cholesky decomposition of a matrix.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m     c, lower \u001b[38;5;241m=\u001b[39m \u001b[43m_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcheck_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_finite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/pai/lib/python3.8/site-packages/scipy/linalg/decomp_cholesky.py:35\u001b[0m, in \u001b[0;36m_cholesky\u001b[0;34m(a, lower, overwrite_a, clean, check_finite)\u001b[0m\n\u001b[1;32m     33\u001b[0m overwrite_a \u001b[38;5;241m=\u001b[39m overwrite_a \u001b[38;5;129;01mor\u001b[39;00m _datacopied(a1, a)\n\u001b[1;32m     34\u001b[0m potrf, \u001b[38;5;241m=\u001b[39m get_lapack_funcs((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpotrf\u001b[39m\u001b[38;5;124m'\u001b[39m,), (a1,))\n\u001b[0;32m---> 35\u001b[0m c, info \u001b[38;5;241m=\u001b[39m \u001b[43mpotrf\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th leading minor of the array is not positive \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefinite\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m info)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# you don't have to change this function\n",
    "def main():\n",
    "    # Load the training dateset and test features\n",
    "    train_x = np.loadtxt('train_x.csv', delimiter=',', skiprows=1)\n",
    "    train_y = np.loadtxt('train_y.csv', delimiter=',', skiprows=1)\n",
    "    test_x = np.loadtxt('test_x.csv', delimiter=',', skiprows=1)\n",
    "\n",
    "    # Extract the city_area information\n",
    "    train_coordinates, train_area_flags, test_coordinates, test_area_flags = extract_area_information(train_x, test_x)\n",
    "    \n",
    "    # Fit the model\n",
    "    print('Training model')\n",
    "    model = Model()\n",
    "    model.train_model(train_y, train_coordinates, train_area_flags)\n",
    "\n",
    "    # Predict on the test features\n",
    "    print('Predicting on test features')\n",
    "    predictions = model.generate_predictions(test_coordinates, test_area_flags)\n",
    "    print(predictions)\n",
    "\n",
    "    if EXTENDED_EVALUATION:\n",
    "        execute_extended_evaluation(model, output_dir='.')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
